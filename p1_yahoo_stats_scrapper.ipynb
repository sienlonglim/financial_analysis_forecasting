{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa7fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "import requests_cache\n",
    "import re\n",
    "\n",
    "\n",
    "#headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "requests_cache.install_cache('yahoo_cache')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44c56d39",
   "metadata": {},
   "source": [
    "<h1>Part 1 - S&P and portfolio web scraper</h1>\n",
    "<h2>Introduction</h2>\n",
    "<p>The Standard and Poor's 500, or simply the S&P 500, is a stock market index tracking the stock performance of 500 large companies listed on stock exchanges in the United States. Having consisting of 11 different sectors and over 500 different companies, the index can be used as a benchmark for a basic stock portfolio diversification in the US stock marker. It is one of the most commonly followed equity indices.</p>\n",
    "    \n",
    "<p>This script scraps data from the yahoo finance statistics page.</p>\n",
    "<img src=\"sample.JPG\">\n",
    "<p>Two sets of data are in focus</p>\n",
    "<ol>\n",
    "    <li>The S&P index constituents.</li>\n",
    "    <li>One's portfolio</li>\n",
    "    </ol>\n",
    "\n",
    "## Item 1 - Function Definitions\n",
    "<h3>Getting updated S&P tickers from slickcharts website</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94aacdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_SnP_tickers(url='https://www.slickcharts.com/sp500', tableclass=\"table-responsive\"):\n",
    "    '''\n",
    "    Function to scrap the latest S&P data from a website containing S&P data\n",
    "    Input:\n",
    "        url = website url\n",
    "        tableclass = name of tableclass containing the data\n",
    "    '''\n",
    "    resp = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    table = soup.find(class_ = tableclass)\n",
    "\n",
    "    table_head = table.find('thead')\n",
    "    header_list = []\n",
    "    ths = table_head.find_all('th')\n",
    "    for th in ths:\n",
    "        header_list.append(th.text.strip())\n",
    "\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    rows = table_body.find_all('tr')\n",
    "    sp_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        sp_data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "    sp_df = pd.DataFrame(np.array(sp_data))\n",
    "    sp_df.columns = header_list\n",
    "    sp_df = sp_df.drop('#', axis=1)\n",
    "    sp_df['Symbol'].replace(regex={r'[\\.]': '-'}, inplace=True) #tickers need to have - instead of . for proper search on yahoo\n",
    "    tickers = sp_df['Symbol'].tolist()\n",
    "    print(f'Number of S&P constituent tickers = {len(tickers)}')\n",
    "    display(sp_df.head())\n",
    "    return sp_df, tickers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500a652",
   "metadata": {},
   "source": [
    "<h3>Retrieving headers of yahoo finance stats page (Optional)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db1dd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yf_headers(ticker_sample): #ticker_sample is any ticker(str) for the purpose of retrieving the headers\n",
    "    #Getting headers\n",
    "    url = f'https://finance.yahoo.com/quote/{ticker_sample}/key-statistics?p={ticker_sample}'\n",
    "    resp = requests.get(url, headers = headers)\n",
    "    print(f'Using {ticker_sample} for headers, status - {resp.status_code}')\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    titles = ['Ticker']\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        ele = cols[0].text.strip() \n",
    "        titles.append(ele)\n",
    "\n",
    "    metrics_df = pd.DataFrame({\"Metrics\":titles})\n",
    "    metrics_df['Metrics'].replace(regex={r'[0-9]$': ''}, inplace = True) #removes the annotations appearing at the end of rows\n",
    "    metrics_df.iloc[24:29,0].replace(regex={r'(\\(.+\\))': ''}, inplace = True) #remove the dates under rows 24-28\n",
    "    metrics = metrics_df['Metrics'].tolist()\n",
    "    print(f'Extraction of headers complete! Total metric columns = {len(metrics)}')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451a933",
   "metadata": {},
   "source": [
    "<h3>Renaming the headers manually to indicate units clearly</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d7af439",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Name',\n",
    " 'Market Cap (B)',\n",
    " 'Enterprise Value (B)',\n",
    " 'Trailing P/E',\n",
    " 'Forward P/E',\n",
    " 'PEG Ratio (5 yr expected)',\n",
    " 'Price/Sales (ttm)',\n",
    " 'Price/Book (mrq)',\n",
    " 'Enterprise Value/Revenue',\n",
    " 'Enterprise Value/EBITDA',\n",
    " 'Beta (5Y Monthly)',\n",
    " '52 Week Change (%)',\n",
    " 'S&P500 52-Week Change (%)',\n",
    " '52 Week High',\n",
    " '52 Week Low',\n",
    " '50-Day Moving Average',\n",
    " '200-Day Moving Average',\n",
    " 'Avg Vol 3 month (M)',\n",
    " 'Avg Vol 10 day (M)',\n",
    " 'Shares Outstanding',\n",
    " 'Implied Shares Outstanding',\n",
    " 'Float',\n",
    " '% Held by Insiders',\n",
    " '% Held by Institutions',\n",
    " 'Shares Short (M)',\n",
    " 'Short Ratio (M)',\n",
    " 'Short % of Float',\n",
    " 'Short % of Shares Outstanding',\n",
    " 'Shares Short',\n",
    " 'Forward Annual Dividend Rate',\n",
    " 'Forward Annual Dividend Yield (%)',\n",
    " 'Trailing Annual Dividend Rate',\n",
    " 'Trailing Annual Dividend Yield (%)',\n",
    " '5 Year Average Dividend Yield',\n",
    " 'Payout Ratio (%)',\n",
    " 'Dividend Date',\n",
    " 'Ex-Dividend Date',\n",
    " 'Last Split Factor (x:1)',\n",
    " 'Last Split Date',\n",
    " 'Fiscal Year Ends',\n",
    " 'Most Recent Quarter (mrq)',\n",
    " 'Profit Margin (%)',\n",
    " 'Operating Margin (ttm) (%)',\n",
    " 'Return on Assets (ttm) (%)',\n",
    " 'Return on Equity (ttm) (%)',\n",
    " 'Revenue (ttm) (B)',\n",
    " 'Revenue Per Share (ttm)',\n",
    " 'Quarterly Revenue Growth (yoy) (%)',\n",
    " 'Gross Profit (ttm) (B)',\n",
    " 'EBITDA (B)',\n",
    " 'Net Income Avi to Common (ttm) (B)',\n",
    " 'Diluted EPS (ttm)',\n",
    " 'Quarterly Earnings Growth (yoy) (%)',\n",
    " 'Total Cash (mrq) (B)',\n",
    " 'Total Cash Per Share (mrq)',\n",
    " 'Total Debt (mrq) (B)',\n",
    " 'Total Debt/Equity (mrq)',\n",
    " 'Current Ratio (mrq)',\n",
    " 'Book Value Per Share (mrq)',\n",
    " 'Operating Cash Flow (ttm) (B)',\n",
    " 'Levered Free Cash Flow (ttm) (B)']\n",
    "\n",
    "#for visually checking if the list referencing is correct\n",
    "#temp = get_yf_headers('AAPL')\n",
    "#test = pd.DataFrame({'Old':temp, 'new':metrics})\n",
    "#test.iloc[0:60,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08135a96",
   "metadata": {},
   "source": [
    "### Scraping and casting ticker stats into 2D list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae6ed47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_ticker(tickers, data_dict, sleeptime=2, batch_interval=50):  \n",
    "    '''\n",
    "    Function take takes in a list of tickers and scraps the yahoo stats into a dictionary.\n",
    "    Input:\n",
    "        tickers : list of tickers\n",
    "        all_data : dictionary to update with the scrapped data, should be created outside the function\n",
    "        sleeptime : time to sleep between scraps\n",
    "        batch_interval : number of scraps before a longer rest\n",
    "        '''\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    #check if there is any existing data in all_data (dictionary), if yes, assigns this run to the next batch number\n",
    "    if data_dict:\n",
    "        batch_number = max(data_dict.keys())+1\n",
    "        print(f'Batch number: {batch_number}')\n",
    "    else:\n",
    "        batch_number = 1\n",
    "    \n",
    "    #initialize the batch_count, and wait_counter (for increasing waits between failed scraps)\n",
    "    batch_count = 0\n",
    "    wait_counter = 1\n",
    "\n",
    "    #initialize list for collecting batch data and list for collecting tickers with errors\n",
    "    batch_data = []\n",
    "    missed_tickers=[]\n",
    "    \n",
    "    try:\n",
    "        for count, ticker in enumerate(tickers):\n",
    "            url = f'https://finance.yahoo.com/quote/{ticker}/key-statistics?p={ticker}'\n",
    "            resp = requests.get(url, headers = headers)\n",
    "            print(f'{ticker} status - {resp.status_code}, {count+1}/{len(tickers)}', end=' ')\n",
    "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "            \n",
    "            title = soup.find(\"h1\")\n",
    "            data= [title.text]\n",
    "            \n",
    "            rows = soup.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_all(\"td\")\n",
    "                ele = cols[1].text.strip()\n",
    "                data.append(ele)\n",
    "            \n",
    "            #to account for errors in the extraction length or data\n",
    "            if len(data)!=len(metrics) or data[1] == 'N/A':\n",
    "                if len(data)!=len(metrics):\n",
    "                    print(f'length error({len(data)} instead of {len(metrics)}) in {ticker}')\n",
    "                elif data[1] == 'N/A':\n",
    "                    print(f'N/A found in Marketcap of {ticker}')\n",
    "                missed_tickers.append(ticker)\n",
    "                print(f'Sleeping for {sleeptime*2*wait_counter}s')\n",
    "                time.sleep(sleeptime*2*wait_counter)\n",
    "                wait_counter +=1\n",
    "            else:\n",
    "                batch_data.append(data)\n",
    "                print(f'complete!')\n",
    "                batch_count +=1\n",
    "                time.sleep(sleeptime)\n",
    "\n",
    "            #code to sleep after a batch\n",
    "            if batch_count == batch_interval:\n",
    "                data_dict[batch_number] = pd.DataFrame(np.array(batch_data))\n",
    "                print(f'\\nLength of info extracted is {len(batch_data)} in batch {batch_number} \\n')\n",
    "                batch_count = 0\n",
    "                batch_number +=1\n",
    "                batch_data = []\n",
    "                print(f'Sleeping for {sleeptime*2}s')\n",
    "                time.sleep(sleeptime*2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        #the final appending for last batch with n smaller than 50\n",
    "        data_dict[batch_number] = pd.DataFrame(np.array(batch_data))\n",
    "        print(f'Length of info extracted is {len(batch_data)} in batch {batch_number}')\n",
    "        end_time = datetime.now()\n",
    "        print('Elapsed time was', (end_time - start_time))\n",
    "        print()\n",
    "        return missed_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cc6a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescrap_missed(missed_tickers, data_dict, max_tries=5):\n",
    "    '''\n",
    "    Extracts tickers that had errors/incomplete info\n",
    "    Input:\n",
    "        list of missed_tickers\n",
    "        max_tries (int) default 5\n",
    "        user_prompt (boolean) prompt to continue if max_tries exceeeded \n",
    "    '''\n",
    "    count = 0\n",
    "    while missed_tickers:\n",
    "        print(f'Extracting missed tickers: Attempt {count+1}')\n",
    "        temp = missed_tickers.copy()\n",
    "        missed_tickers = scrap_ticker(temp, data_dict, sleeptime=2)\n",
    "        count +=1\n",
    "        if count >= max_tries:\n",
    "            break\n",
    "    print('Unresolved tickers:', missed_tickers)\n",
    "    return missed_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f2f49",
   "metadata": {},
   "source": [
    "<h3>Casting the dataframe and cleaning all the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "052e7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(all_data, metrics, display_progress=False):\n",
    "    '''\n",
    "    Function to cast and clean the dataframe via the following:\n",
    "    1. Cast dictionary(all_data) into a pandas dataframe\n",
    "    2. Format strings into numbers according (large number format)\n",
    "    3. Clean stocksplit ratios \n",
    "    4. Recast dates into datetime format\n",
    "\n",
    "    Inputs:\n",
    "    all_data : scrapped data [dictionary]\n",
    "    metrics : list of column headers [list]\n",
    "    display_progress: boolean to show processes\n",
    "    '''\n",
    "    #Casting the dataframe\n",
    "    frames = [all_data[x] for x in all_data]\n",
    "    all_data_df = pd.concat(frames)\n",
    "    all_data_df.columns = metrics\n",
    "\n",
    "    # Save the name list first to ensure correct order of tickers scrapped\n",
    "    # Split the name into company name and ticker\n",
    "\n",
    "    def extract_tickers(name):\n",
    "        ticker_symbol = re.findall('\\(([a-zA-Z\\-]+)\\)', name)\n",
    "        try:\n",
    "            # Check for accidental extractions\n",
    "            if len(ticker_symbol)>1:\n",
    "                index = -1\n",
    "            else:\n",
    "                index = 0\n",
    "            return ticker_symbol[index]\n",
    "        except IndexError:\n",
    "            print(f'No ticker found for company: {name}')\n",
    "            return np.nan\n",
    "\n",
    "    all_data_tickers = all_data_df['Name'].apply(extract_tickers)\n",
    "    all_data_name = all_data_df['Name'].apply(lambda x: x.split('(')[0])\n",
    "\n",
    "\n",
    "    if display_progress:\n",
    "        print('Casting data, index and columns to build the dataframe')\n",
    "        display(all_data_df.head()) \n",
    "\n",
    "    def _num_reformat(x):\n",
    "        '''\n",
    "        Reformats large sums (Billion, million, thousand) and removing (%,) values\n",
    "        Casts numerical values into float type\n",
    "        '''\n",
    "        x = re.sub(\"[,]\", \"\", x)\n",
    "        if x[-1] == 'T':\n",
    "            x = round(float(x[:-1])*1000,2)\n",
    "        elif x[-1] == 'B':\n",
    "            x = round(float(x[:-1]),2)\n",
    "        elif x[-1] == 'M':\n",
    "            x = round(float(x[:-1])*0.001,2)\n",
    "        elif x[-1] == 'k':\n",
    "            x = round(float(x[:-1])*0.000001,2)\n",
    "        elif x[-1] == '%':\n",
    "            x = round(float(x[:-1]),2)             \n",
    "        elif x == \"N/A\":\n",
    "            x = 0\n",
    "        return x\n",
    "\n",
    "    cleaned_df = all_data_df.iloc[:,1:].applymap(_num_reformat)\n",
    "\n",
    "    # Insert back columns for progress display\n",
    "    cleaned_df.insert(0, 'Name', all_data_name)\n",
    "    if display_progress:\n",
    "        print('Reformatting large sums (Billion, million, thousand) and removing (%,) values')\n",
    "        display(cleaned_df.head())\n",
    "    \n",
    "    def _stocksplits(x):\n",
    "        '''\n",
    "        Changes split factors into x:1 whole ratios\n",
    "        '''\n",
    "        if type(x)==str:\n",
    "            x = x.split(':')\n",
    "            return round(int(x[0])/ int(x[1]),2)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    cleaned_df['Last Split Factor (x:1)'] = cleaned_df['Last Split Factor (x:1)'].apply(_stocksplits)\n",
    "    if display_progress:\n",
    "        print('Handling the stock split factor column')\n",
    "        display(cleaned_df.iloc[:,[0,37]].head())\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _date_conversion(x):\n",
    "        '''\n",
    "        Converts dates int datetime format at the end of the dataframe\n",
    "        '''\n",
    "        if x == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            x = str(x)\n",
    "            return datetime.strptime(x, '%b %d %Y').date()\n",
    "\n",
    "    # Slicing columns which should be dates\n",
    "    dates = cleaned_df.iloc[:,[35, 36, 38, 39, 40]]\n",
    "    dates = dates.applymap(_date_conversion)\n",
    "    dates = dates.replace({0:np.nan})\n",
    "\n",
    "    if display_progress:\n",
    "        print('Converting dates to datetime format')\n",
    "        display(dates.head())\n",
    "\n",
    "    # Drop the old date columns, add datetime columns and add back all ticker & company names\n",
    "    final_df = cleaned_df.drop(cleaned_df.columns[[0, 35, 36, 38, 39, 40]], axis = 1).astype('float64')\n",
    "    final_df = pd.concat([final_df, dates], axis = 1)\n",
    "    final_df.insert(0, 'Ticker', all_data_tickers)\n",
    "    ticker_df = pd.concat([all_data_tickers, all_data_name], axis=1)\n",
    "    ticker_df.columns = ['Ticker', 'Name']\n",
    "    \n",
    "    if display_progress:\n",
    "        print('Final_df cleaned')\n",
    "        display(final_df.head())\n",
    "    \n",
    "    #return the completed pandas dataframe\n",
    "    return final_df, ticker_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36658f62",
   "metadata": {},
   "source": [
    "## Option 1 - S&P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2746e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of S&P constituent tickers = 503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Chg</th>\n",
       "      <th>% Chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.104214</td>\n",
       "      <td>164.97</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>(-0.35%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>6.224815</td>\n",
       "      <td>286.50</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>(-1.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com Inc.</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2.633905</td>\n",
       "      <td>102.72</td>\n",
       "      <td>0.32</td>\n",
       "      <td>(0.32%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1.878221</td>\n",
       "      <td>267.32</td>\n",
       "      <td>2.69</td>\n",
       "      <td>(1.02%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc. Class A</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1.846088</td>\n",
       "      <td>108.93</td>\n",
       "      <td>1.50</td>\n",
       "      <td>(1.40%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Symbol    Weight   Price    Chg     % Chg\n",
       "0             Apple Inc.   AAPL  7.104214  164.97  -0.59  (-0.35%)\n",
       "1  Microsoft Corporation   MSFT  6.224815  286.50  -3.34  (-1.15%)\n",
       "2        Amazon.com Inc.   AMZN  2.633905  102.72   0.32   (0.32%)\n",
       "3     NVIDIA Corporation   NVDA  1.878221  267.32   2.69   (1.02%)\n",
       "4  Alphabet Inc. Class A  GOOGL  1.846088  108.93   1.50   (1.40%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp_df, tickers = scrap_SnP_tickers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dfff801",
   "metadata": {},
   "source": [
    "## Option 2 - Personal portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b26cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tickers = pd.read_csv('portfolio_tickers.csv') #input file with a list of portfolio tickers\n",
    "tickers = input_tickers['Tickers'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bef5f952",
   "metadata": {},
   "source": [
    "### Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16df3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL status - 200, 1/503 complete!\n",
      "MSFT status - 200, 2/503 complete!\n",
      "AMZN status - 200, 3/503 complete!\n",
      "NVDA status - 200, 4/503 complete!\n",
      "GOOGL status - 200, 5/503 complete!\n",
      "BRK-B status - 200, 6/503 complete!\n",
      "GOOG status - 200, 7/503 complete!\n",
      "TSLA status - 200, 8/503 complete!\n",
      "UNH status - 200, 9/503 complete!\n",
      "META status - 200, 10/503 complete!\n",
      "XOM status - 200, 11/503 complete!\n",
      "JNJ status - 200, 12/503 complete!\n",
      "JPM status - 200, 13/503 complete!\n",
      "V status - 200, 14/503 complete!\n",
      "PG status - 200, 15/503 complete!\n",
      "MA status - 200, 16/503 complete!\n",
      "CVX status - 200, 17/503 complete!\n",
      "HD status - 200, 18/503 complete!\n",
      "LLY status - 200, 19/503 complete!\n",
      "MRK status - 200, 20/503 complete!\n",
      "ABBV status - 200, 21/503 complete!\n",
      "AVGO status - 200, 22/503 complete!\n",
      "PEP status - 200, 23/503 complete!\n",
      "KO status - 200, 24/503 complete!\n",
      "PFE status - 200, 25/503 complete!\n",
      "TMO status - 200, 26/503 complete!\n",
      "COST status - 200, 27/503 complete!\n",
      "MCD status - 200, 28/503 complete!\n",
      "WMT status - 200, 29/503 complete!\n",
      "CSCO status - 200, 30/503 complete!\n",
      "BAC status - 200, 31/503 complete!\n",
      "CRM status - 200, 32/503 complete!\n",
      "DIS status - 200, 33/503 complete!\n",
      "ABT status - 200, 34/503 complete!\n",
      "ACN status - 200, 35/503 complete!\n",
      "LIN status - 200, 36/503 complete!\n",
      "ADBE status - 200, 37/503 complete!\n",
      "DHR status - 200, 38/503 complete!\n",
      "VZ status - 200, 39/503 complete!\n",
      "TXN status - 200, 40/503 complete!\n",
      "CMCSA status - 200, 41/503 complete!\n",
      "NKE status - 200, 42/503 complete!\n",
      "NEE status - 200, 43/503 complete!\n",
      "PM status - 200, 44/503 complete!\n",
      "NFLX status - 200, 45/503 complete!\n",
      "WFC status - 200, 46/503 complete!\n",
      "BMY status - 200, 47/503 complete!\n",
      "RTX status - 200, 48/503 complete!\n",
      "AMD status - 200, 49/503 complete!\n",
      "ORCL status - 200, 50/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 1 \n",
      "\n",
      "Sleeping for 4s\n",
      "T status - 200, 51/503 complete!\n",
      "UPS status - 200, 52/503 complete!\n",
      "QCOM status - 200, 53/503 complete!\n",
      "AMGN status - 200, 54/503 complete!\n",
      "COP status - 200, 55/503 complete!\n",
      "INTC status - 200, 56/503 complete!\n",
      "HON status - 200, 57/503 complete!\n",
      "INTU status - 200, 58/503 complete!\n",
      "SBUX status - 200, 59/503 complete!\n",
      "LOW status - 200, 60/503 complete!\n",
      "UNP status - 200, 61/503 complete!\n",
      "BA status - 200, 62/503 complete!\n",
      "ELV status - 200, 63/503 complete!\n",
      "IBM status - 200, 64/503 complete!\n",
      "CAT status - 200, 65/503 complete!\n",
      "SPGI status - 200, 66/503 complete!\n",
      "GS status - 200, 67/503 complete!\n",
      "PLD status - 200, 68/503 complete!\n",
      "MS status - 200, 69/503 complete!\n",
      "LMT status - 200, 70/503 complete!\n",
      "MDT status - 200, 71/503 complete!\n",
      "DE status - 200, 72/503 complete!\n",
      "GILD status - 200, 73/503 complete!\n",
      "GE status - 200, 74/503 complete!\n",
      "BKNG status - 200, 75/503 complete!\n",
      "BLK status - 200, 76/503 complete!\n",
      "SYK status - 200, 77/503 complete!\n",
      "NOW status - 200, 78/503 complete!\n",
      "AMT status - 200, 79/503 complete!\n",
      "CVS status - 200, 80/503 complete!\n",
      "AXP status - 200, 81/503 complete!\n",
      "MDLZ status - 200, 82/503 complete!\n",
      "ADI status - 200, 83/503 complete!\n",
      "AMAT status - 200, 84/503 complete!\n",
      "ISRG status - 200, 85/503 complete!\n",
      "C status - 200, 86/503 complete!\n",
      "ADP status - 200, 87/503 complete!\n",
      "TJX status - 200, 88/503 complete!\n",
      "REGN status - 200, 89/503 complete!\n",
      "TMUS status - 200, 90/503 complete!\n",
      "VRTX status - 200, 91/503 complete!\n",
      "PYPL status - 200, 92/503 complete!\n",
      "MMC status - 200, 93/503 complete!\n",
      "CB status - 200, 94/503 complete!\n",
      "ZTS status - 200, 95/503 complete!\n",
      "PGR status - 200, 96/503 complete!\n",
      "MO status - 200, 97/503 complete!\n",
      "CI status - 200, 98/503 complete!\n",
      "SO status - 200, 99/503 complete!\n",
      "SCHW status - 200, 100/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 2 \n",
      "\n",
      "Sleeping for 4s\n",
      "DUK status - 200, 101/503 complete!\n",
      "TGT status - 200, 102/503 complete!\n",
      "SLB status - 200, 103/503 complete!\n",
      "BSX status - 200, 104/503 complete!\n",
      "FISV status - 200, 105/503 complete!\n",
      "BDX status - 200, 106/503 complete!\n",
      "EOG status - 200, 107/503 complete!\n",
      "MU status - 200, 108/503 complete!\n",
      "NOC status - 200, 109/503 complete!\n",
      "CME status - 200, 110/503 complete!\n",
      "LRCX status - 200, 111/503 complete!\n",
      "AON status - 200, 112/503 complete!\n",
      "HUM status - 200, 113/503 complete!\n",
      "EQIX status - 200, 114/503 complete!\n",
      "ITW status - 200, 115/503 complete!\n",
      "CL status - 200, 116/503 complete!\n",
      "ETN status - 200, 117/503 complete!\n",
      "CSX status - 200, 118/503 complete!\n",
      "APD status - 200, 119/503 complete!\n",
      "WM status - 200, 120/503 complete!\n",
      "FCX status - 200, 121/503 complete!\n",
      "ATVI status - 200, 122/503 complete!\n",
      "ICE status - 200, 123/503 complete!\n",
      "CDNS status - 200, 124/503 complete!\n",
      "MPC status - 200, 125/503 complete!\n",
      "MMM status - 200, 126/503 complete!\n",
      "EL status - 200, 127/503 complete!\n",
      "SNPS status - 200, 128/503 complete!\n",
      "CCI status - 200, 129/503 complete!\n",
      "HCA status - 200, 130/503 complete!\n",
      "ORLY status - 200, 131/503 complete!\n",
      "PXD status - 200, 132/503 complete!\n",
      "FDX status - 200, 133/503 complete!\n",
      "SHW status - 200, 134/503 complete!\n",
      "MRNA status - 200, 135/503 complete!\n",
      "EW status - 200, 136/503 complete!\n",
      "KLAC status - 200, 137/503 complete!\n",
      "GIS status - 200, 138/503 complete!\n",
      "GD status - 200, 139/503 complete!\n",
      "VLO status - 200, 140/503 complete!\n",
      "MCK status - 200, 141/503 complete!\n",
      "PSX status - 200, 142/503 complete!\n",
      "USB status - 200, 143/503 complete!\n",
      "AZO status - 200, 144/503 complete!\n",
      "F status - 200, 145/503 complete!\n",
      "PNC status - 200, 146/503 complete!\n",
      "EMR status - 200, 147/503 complete!\n",
      "D status - 200, 148/503 complete!\n",
      "SRE status - 200, 149/503 complete!\n",
      "DG status - 200, 150/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 3 \n",
      "\n",
      "Sleeping for 4s\n",
      "MSI status - 200, 151/503 complete!\n",
      "AEP status - 200, 152/503 complete!\n",
      "GM status - 200, 153/503 complete!\n",
      "PSA status - 200, 154/503 complete!\n",
      "MCO status - 200, 155/503 complete!\n",
      "CMG status - 200, 156/503 complete!\n",
      "NSC status - 200, 157/503 complete!\n",
      "OXY status - 200, 158/503 complete!\n",
      "ROP status - 200, 159/503 complete!\n",
      "APH status - 200, 160/503 complete!\n",
      "KMB status - 200, 161/503 complete!\n",
      "DXCM status - 200, 162/503 complete!\n",
      "TFC status - 200, 163/503 complete!\n",
      "CTVA status - 200, 164/503 complete!\n",
      "ADM status - 200, 165/503 complete!\n",
      "NXPI status - 200, 166/503 complete!\n",
      "MAR status - 200, 167/503 complete!\n",
      "FTNT status - 200, 168/503 complete!\n",
      "MCHP status - 200, 169/503 complete!\n",
      "MSCI status - 200, 170/503 complete!\n",
      "EXC status - 200, 171/503 complete!\n",
      "ADSK status - 200, 172/503 complete!\n",
      "AJG status - 200, 173/503 complete!\n",
      "BIIB status - 200, 174/503 complete!\n",
      "A status - 200, 175/503 complete!\n",
      "ECL status - 200, 176/503 complete!\n",
      "PH status - 200, 177/503 complete!\n",
      "HES status - 200, 178/503 complete!\n",
      "ANET status - 200, 179/503 complete!\n",
      "NEM status - 200, 180/503 complete!\n",
      "TT status - 200, 181/503 complete!\n",
      "MNST status - 200, 182/503 complete!\n",
      "TEL status - 200, 183/503 complete!\n",
      "TRV status - 200, 184/503 complete!\n",
      "DOW status - 200, 185/503 complete!\n",
      "IDXX status - 200, 186/503 complete!\n",
      "CTAS status - 200, 187/503 complete!\n",
      "JCI status - 200, 188/503 complete!\n",
      "MET status - 200, 189/503 complete!\n",
      "TDG status - 200, 190/503 complete!\n",
      "XEL status - 200, 191/503 complete!\n",
      "O status - 200, 192/503 complete!\n",
      "LHX status - 200, 193/503 complete!\n",
      "AIG status - 200, 194/503 complete!\n",
      "CNC status - 200, 195/503 complete!\n",
      "HLT status - 200, 196/503 complete!\n",
      "HSY status - 200, 197/503 complete!\n",
      "YUM status - 200, 198/503 complete!\n",
      "SYY status - 200, 199/503 complete!\n",
      "IQV status - 200, 200/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 4 \n",
      "\n",
      "Sleeping for 4s\n",
      "AFL status - 200, 201/503 complete!\n",
      "PCAR status - 200, 202/503 complete!\n",
      "NUE status - 200, 203/503 complete!\n",
      "WMB status - 200, 204/503 complete!\n",
      "CARR status - 200, 205/503 complete!\n",
      "STZ status - 200, 206/503 complete!\n",
      "COF status - 200, 207/503 complete!\n",
      "CHTR status - 200, 208/503 complete!\n",
      "ILMN status - 200, 209/503 complete!\n",
      "ROST status - 200, 210/503 complete!\n",
      "DVN status - 200, 211/503 complete!\n",
      "SPG status - 200, 212/503 complete!\n",
      "MTD status - 200, 213/503 complete!\n",
      "WELL status - 200, 214/503 complete!\n",
      "KMI status - 200, 215/503 complete!\n",
      "PAYX status - 200, 216/503 complete!\n",
      "ED status - 200, 217/503 complete!\n",
      "OTIS status - 200, 218/503 complete!\n",
      "BK status - 200, 219/503 complete!\n",
      "EA status - 200, 220/503 complete!\n",
      "FIS status - 200, 221/503 complete!\n",
      "ON status - 200, 222/503 complete!\n",
      "RMD status - 200, 223/503 complete!\n",
      "CPRT status - 200, 224/503 complete!\n",
      "VICI status - 200, 225/503 complete!\n",
      "AMP status - 200, 226/503 complete!\n",
      "CMI status - 200, 227/503 complete!\n",
      "DD status - 200, 228/503 complete!\n",
      "PPG status - 200, 229/503 complete!\n",
      "AME status - 200, 230/503 complete!\n",
      "ROK status - 200, 231/503 complete!\n",
      "PEG status - 200, 232/503 complete!\n",
      "DLTR status - 200, 233/503 complete!\n",
      "CTSH status - 200, 234/503 complete!\n",
      "PRU status - 200, 235/503 complete!\n",
      "KHC status - 200, 236/503 complete!\n",
      "WBD status - 200, 237/503 complete!\n",
      "WEC status - 200, 238/503 complete!\n",
      "HAL status - 200, 239/503 complete!\n",
      "DHI status - 200, 240/503 complete!\n",
      "KR status - 200, 241/503 complete!\n",
      "VRSK status - 200, 242/503 complete!\n",
      "ALL status - 200, 243/503 complete!\n",
      "ODFL status - 200, 244/503 complete!\n",
      "GEHC status - 200, 245/503 complete!\n",
      "FAST status - 200, 246/503 complete!\n",
      "OKE status - 200, 247/503 complete!\n",
      "KDP status - 200, 248/503 complete!\n",
      "BKR status - 200, 249/503 complete!\n",
      "AWK status - 200, 250/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 5 \n",
      "\n",
      "Sleeping for 4s\n",
      "GWW status - 200, 251/503 complete!\n",
      "APTV status - 200, 252/503 complete!\n",
      "SBAC status - 200, 253/503 complete!\n",
      "KEYS status - 200, 254/503 complete!\n",
      "ENPH status - 200, 255/503 complete!\n",
      "CSGP status - 200, 256/503 complete!\n",
      "RSG status - 200, 257/503 complete!\n",
      "GPN status - 200, 258/503 complete!\n",
      "ANSS status - 200, 259/503 complete!\n",
      "EIX status - 200, 260/503 complete!\n",
      "ZBH status - 200, 261/503 complete!\n",
      "ES status - 200, 262/503 complete!\n",
      "STT status - 200, 263/503 complete!\n",
      "WST status - 200, 264/503 complete!\n",
      "ABC status - 200, 265/503 complete!\n",
      "ULTA status - 200, 266/503 complete!\n",
      "PCG status - 200, 267/503 complete!\n",
      "DFS status - 200, 268/503 complete!\n",
      "FANG status - 200, 269/503 complete!\n",
      "GLW status - 200, 270/503 complete!\n",
      "LEN status - 200, 271/503 complete!\n",
      "DLR status - 200, 272/503 complete!\n",
      "TSCO status - 200, 273/503 complete!\n",
      "ACGL status - 200, 274/503 complete!\n",
      "HPQ status - 200, 275/503 complete!\n",
      "URI status - 200, 276/503 complete!\n",
      "WBA status - 200, 277/503 complete!\n",
      "CDW status - 200, 278/503 complete!\n",
      "WTW status - 200, 279/503 complete!\n",
      "IT status - 200, 280/503 complete!\n",
      "TROW status - 200, 281/503 complete!\n",
      "CEG status - 200, 282/503 complete!\n",
      "ALGN status - 200, 283/503 complete!\n",
      "LYB status - 200, 284/503 complete!\n",
      "EFX status - 200, 285/503 complete!\n",
      "IFF status - 200, 286/503 complete!\n",
      "AVB status - 200, 287/503 complete!\n",
      "ALB status - 200, 288/503 complete!\n",
      "FTV status - 200, 289/503 complete!\n",
      "EBAY status - 200, 290/503 complete!\n",
      "PWR status - 200, 291/503 complete!\n",
      "AEE status - 200, 292/503 complete!\n",
      "GPC status - 200, 293/503 complete!\n",
      "WY status - 200, 294/503 complete!\n",
      "IR status - 200, 295/503 complete!\n",
      "HIG status - 200, 296/503 complete!\n",
      "VMC status - 200, 297/503 complete!\n",
      "CBRE status - 200, 298/503 complete!\n",
      "FE status - 200, 299/503 complete!\n",
      "ETR status - 200, 300/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 6 \n",
      "\n",
      "Sleeping for 4s\n",
      "PODD status - 200, 301/503 complete!\n",
      "DTE status - 200, 302/503 complete!\n",
      "CHD status - 200, 303/503 complete!\n",
      "BAX status - 200, 304/503 complete!\n",
      "MLM status - 200, 305/503 complete!\n",
      "MKC status - 200, 306/503 complete!\n",
      "DAL status - 200, 307/503 complete!\n",
      "MPWR status - 200, 308/503 complete!\n",
      "EXR status - 200, 309/503 complete!\n",
      "HOLX status - 200, 310/503 complete!\n",
      "CAH status - 200, 311/503 complete!\n",
      "PPL status - 200, 312/503 complete!\n",
      "FSLR status - 200, 313/503 complete!\n",
      "TDY status - 200, 314/503 complete!\n",
      "DOV status - 200, 315/503 complete!\n",
      "HPE status - 200, 316/503 complete!\n",
      "LH status - 200, 317/503 complete!\n",
      "EQR status - 200, 318/503 complete!\n",
      "CTRA status - 200, 319/503 complete!\n",
      "VRSN status - 200, 320/503 complete!\n",
      "MTB status - 200, 321/503 complete!\n",
      "CLX status - 200, 322/503 complete!\n",
      "TTWO status - 200, 323/503 complete!\n",
      "CNP status - 200, 324/503 complete!\n",
      "STE status - 200, 325/503 complete!\n",
      "OMC status - 200, 326/503 complete!\n",
      "LUV status - 200, 327/503 complete!\n",
      "XYL status - 200, 328/503 complete!\n",
      "ARE status - 200, 329/503 complete!\n",
      "LVS status - 200, 330/503 complete!\n",
      "NDAQ status - 200, 331/503 complete!\n",
      "DRI status - 200, 332/503 complete!\n",
      "COO status - 200, 333/503 complete!\n",
      "WAT status - 200, 334/503 complete!\n",
      "NTRS status - 200, 335/503 complete!\n",
      "INVH status - 200, 336/503 complete!\n",
      "FITB status - 200, 337/503 complete!\n",
      "WAB status - 200, 338/503 complete!\n",
      "CMS status - 200, 339/503 complete!\n",
      "TSN status - 200, 340/503 complete!\n",
      "RJF status - 200, 341/503 complete!\n",
      "CAG status - 200, 342/503 complete!\n",
      "FICO status - 200, 343/503 complete!\n",
      "EXPD status - 200, 344/503 complete!\n",
      "CINF status - 200, 345/503 complete!\n",
      "MOH status - 200, 346/503 complete!\n",
      "VTR status - 200, 347/503 complete!\n",
      "STLD status - 200, 348/503 complete!\n",
      "K status - 200, 349/503 complete!\n",
      "SWKS status - 200, 350/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 7 \n",
      "\n",
      "Sleeping for 4s\n",
      "PKI status - 200, 351/503 complete!\n",
      "RF status - 200, 352/503 complete!\n",
      "TRGP status - 200, 353/503 complete!\n",
      "BR status - 200, 354/503 complete!\n",
      "SEDG status - 200, 355/503 complete!\n",
      "EPAM status - 200, 356/503 complete!\n",
      "AES status - 200, 357/503 complete!\n",
      "PFG status - 200, 358/503 complete!\n",
      "MAA status - 200, 359/503 complete!\n",
      "NVR status - 200, 360/503 complete!\n",
      "AMCR status - 200, 361/503 complete!\n",
      "IEX status - 200, 362/503 complete!\n",
      "SJM status - 200, 363/503 complete!\n",
      "ATO status - 200, 364/503 complete!\n",
      "MRO status - 200, 365/503 complete!\n",
      "DGX status - 200, 366/503 complete!\n",
      "BALL status - 200, 367/503 complete!\n",
      "HBAN status - 200, 368/503 complete!\n",
      "FLT status - 200, 369/503 complete!\n",
      "HWM status - 200, 370/503 complete!\n",
      "FDS status - 200, 371/503 complete!\n",
      "TER status - 200, 372/503 complete!\n",
      "MOS status - 200, 373/503 complete!\n",
      "ZBRA status - 200, 374/503 complete!\n",
      "LW status - 200, 375/503 complete!\n",
      "IRM status - 200, 376/503 complete!\n",
      "FMC status - 200, 377/503 complete!\n",
      "GRMN status - 200, 378/503 complete!\n",
      "TYL status - 200, 379/503 complete!\n",
      "CF status - 200, 380/503 complete!\n",
      "J status - 200, 381/503 complete!\n",
      "IPG status - 200, 382/503 complete!\n",
      "PAYC status - 200, 383/503 complete!\n",
      "BBY status - 200, 384/503 complete!\n",
      "AVY status - 200, 385/503 complete!\n",
      "NTAP status - 200, 386/503 complete!\n",
      "JBHT status - 200, 387/503 complete!\n",
      "CFG status - 200, 388/503 complete!\n",
      "TXT status - 200, 389/503 complete!\n",
      "RE status - 200, 390/503 complete!\n",
      "EVRG status - 200, 391/503 complete!\n",
      "CBOE status - 200, 392/503 complete!\n",
      "LKQ status - 200, 393/503 complete!\n",
      "BG status - 200, 394/503 complete!\n",
      "INCY status - 200, 395/503 complete!\n",
      "MGM status - 200, 396/503 complete!\n",
      "BRO status - 200, 397/503 complete!\n",
      "LNT status - 200, 398/503 complete!\n",
      "UAL status - 200, 399/503 complete!\n",
      "PTC status - 200, 400/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 8 \n",
      "\n",
      "Sleeping for 4s\n",
      "PHM status - 200, 401/503 complete!\n",
      "EXPE status - 200, 402/503 complete!\n",
      "ESS status - 200, 403/503 complete!\n",
      "RCL status - 200, 404/503 complete!\n",
      "PKG status - 200, 405/503 complete!\n",
      "POOL status - 200, 406/503 complete!\n",
      "APA status - 200, 407/503 complete!\n",
      "TECH status - 200, 408/503 complete!\n",
      "AKAM status - 200, 409/503 complete!\n",
      "IP status - 200, 410/503 complete!\n",
      "SYF status - 200, 411/503 complete!\n",
      "MKTX status - 200, 412/503 complete!\n",
      "WRB status - 200, 413/503 complete!\n",
      "SNA status - 200, 414/503 complete!\n",
      "STX status - 200, 415/503 complete!\n",
      "ETSY status - 200, 416/503 complete!\n",
      "LDOS status - 200, 417/503 complete!\n",
      "TRMB status - 200, 418/503 complete!\n",
      "TFX status - 200, 419/503 complete!\n",
      "UDR status - 200, 420/503 complete!\n",
      "VTRS status - 200, 421/503 complete!\n",
      "EQT status - 200, 422/503 complete!\n",
      "DPZ status - 200, 423/503 complete!\n",
      "WDC status - 200, 424/503 complete!\n",
      "NDSN status - 200, 425/503 complete!\n",
      "PEAK status - 200, 426/503 complete!\n",
      "HST status - 200, 427/503 complete!\n",
      "SWK status - 200, 428/503 complete!\n",
      "HRL status - 200, 429/503 complete!\n",
      "JKHY status - 200, 430/503 complete!\n",
      "WYNN status - 200, 431/503 complete!\n",
      "KIM status - 200, 432/503 complete!\n",
      "KEY status - 200, 433/503 complete!\n",
      "CPT status - 200, 434/503 complete!\n",
      "BWA status - 200, 435/503 complete!\n",
      "NI status - 200, 436/503 complete!\n",
      "CTLT status - 200, 437/503 complete!\n",
      "BF-B status - 200, 438/503 complete!\n",
      "CHRW status - 200, 439/503 complete!\n",
      "HSIC status - 200, 440/503 complete!\n",
      "CPB status - 200, 441/503 complete!\n",
      "PARA status - 200, 442/503 complete!\n",
      "KMX status - 200, 443/503 complete!\n",
      "CE status - 200, 444/503 complete!\n",
      "L status - 200, 445/503 complete!\n",
      "MAS status - 200, 446/503 complete!\n",
      "JNPR status - 200, 447/503 complete!\n",
      "TAP status - 200, 448/503 complete!\n",
      "CRL status - 200, 449/503 complete!\n",
      "FOXA status - 200, 450/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 9 \n",
      "\n",
      "Sleeping for 4s\n",
      "CDAY status - 200, 451/503 complete!\n",
      "BIO status - 200, 452/503 complete!\n",
      "GEN status - 200, 453/503 complete!\n",
      "TPR status - 200, 454/503 complete!\n",
      "MTCH status - 200, 455/503 complete!\n",
      "EMN status - 200, 456/503 complete!\n",
      "LYV status - 200, 457/503 complete!\n",
      "CCL status - 200, 458/503 complete!\n",
      "GL status - 200, 459/503 complete!\n",
      "QRVO status - 200, 460/503 complete!\n",
      "CZR status - 200, 461/503 complete!\n",
      "REG status - 200, 462/503 complete!\n",
      "ROL status - 200, 463/503 complete!\n",
      "ALLE status - 200, 464/503 complete!\n",
      "PNW status - 200, 465/503 complete!\n",
      "XRAY status - 200, 466/503 complete!\n",
      "PNR status - 200, 467/503 complete!\n",
      "UHS status - 200, 468/503 complete!\n",
      "FFIV status - 200, 469/503 complete!\n",
      "AOS status - 200, 470/503 complete!\n",
      "AAL status - 200, 471/503 complete!\n",
      "NRG status - 200, 472/503 complete!\n",
      "HII status - 200, 473/503 complete!\n",
      "RHI status - 200, 474/503 complete!\n",
      "BBWI status - 200, 475/503 complete!\n",
      "BEN status - 200, 476/503 complete!\n",
      "WRK status - 200, 477/503 complete!\n",
      "IVZ status - 200, 478/503 complete!\n",
      "AAP status - 200, 479/503 complete!\n",
      "WHR status - 200, 480/503 complete!\n",
      "BXP status - 200, 481/503 complete!\n",
      "VFC status - 200, 482/503 complete!\n",
      "FRT status - 200, 483/503 complete!\n",
      "SEE status - 200, 484/503 complete!\n",
      "NWSA status - 200, 485/503 complete!\n",
      "HAS status - 200, 486/503 complete!\n",
      "GNRC status - 200, 487/503 complete!\n",
      "AIZ status - 200, 488/503 complete!\n",
      "OGN status - 200, 489/503 complete!\n",
      "DXC status - 200, 490/503 complete!\n",
      "CMA status - 200, 491/503 complete!\n",
      "NCLH status - 200, 492/503 complete!\n",
      "ALK status - 200, 493/503 complete!\n",
      "MHK status - 200, 494/503 complete!\n",
      "RL status - 200, 495/503 complete!\n",
      "DVA status - 200, 496/503 complete!\n",
      "ZION status - 200, 497/503 complete!\n",
      "NWL status - 200, 498/503 complete!\n",
      "FOX status - 200, 499/503 complete!\n",
      "LNC status - 200, 500/503 complete!\n",
      "\n",
      "Length of info extracted is 50 in batch 10 \n",
      "\n",
      "Sleeping for 4s\n",
      "FRC status - 200, 501/503 complete!\n",
      "NWS status - 200, 502/503 complete!\n",
      "DISH status - 200, 503/503 complete!\n",
      "Length of info extracted is 3 in batch 11\n",
      "Elapsed time was 0:26:49.277571\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Market Cap (B)</th>\n",
       "      <th>Enterprise Value (B)</th>\n",
       "      <th>Trailing P/E</th>\n",
       "      <th>Forward P/E</th>\n",
       "      <th>PEG Ratio (5 yr expected)</th>\n",
       "      <th>Price/Sales (ttm)</th>\n",
       "      <th>Price/Book (mrq)</th>\n",
       "      <th>Enterprise Value/Revenue</th>\n",
       "      <th>Enterprise Value/EBITDA</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Debt/Equity (mrq)</th>\n",
       "      <th>Current Ratio (mrq)</th>\n",
       "      <th>Book Value Per Share (mrq)</th>\n",
       "      <th>Operating Cash Flow (ttm) (B)</th>\n",
       "      <th>Levered Free Cash Flow (ttm) (B)</th>\n",
       "      <th>Dividend Date</th>\n",
       "      <th>Ex-Dividend Date</th>\n",
       "      <th>Last Split Date</th>\n",
       "      <th>Fiscal Year Ends</th>\n",
       "      <th>Most Recent Quarter (mrq)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2540.00</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>27.30</td>\n",
       "      <td>27.17</td>\n",
       "      <td>2.72</td>\n",
       "      <td>6.72</td>\n",
       "      <td>44.85</td>\n",
       "      <td>6.72</td>\n",
       "      <td>20.34</td>\n",
       "      <td>...</td>\n",
       "      <td>195.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3.58</td>\n",
       "      <td>109.19</td>\n",
       "      <td>84.73</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2110.00</td>\n",
       "      <td>2070.00</td>\n",
       "      <td>31.43</td>\n",
       "      <td>26.11</td>\n",
       "      <td>2.13</td>\n",
       "      <td>10.39</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.12</td>\n",
       "      <td>20.92</td>\n",
       "      <td>...</td>\n",
       "      <td>42.58</td>\n",
       "      <td>1.93</td>\n",
       "      <td>24.59</td>\n",
       "      <td>84.39</td>\n",
       "      <td>44.61</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.82</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.98</td>\n",
       "      <td>7.01</td>\n",
       "      <td>2.13</td>\n",
       "      <td>28.53</td>\n",
       "      <td>...</td>\n",
       "      <td>116.36</td>\n",
       "      <td>0.94</td>\n",
       "      <td>14.26</td>\n",
       "      <td>46.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>671.07</td>\n",
       "      <td>669.81</td>\n",
       "      <td>156.14</td>\n",
       "      <td>60.24</td>\n",
       "      <td>3.38</td>\n",
       "      <td>25.25</td>\n",
       "      <td>30.36</td>\n",
       "      <td>24.83</td>\n",
       "      <td>111.88</td>\n",
       "      <td>...</td>\n",
       "      <td>54.44</td>\n",
       "      <td>3.52</td>\n",
       "      <td>8.96</td>\n",
       "      <td>5.64</td>\n",
       "      <td>4.53</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>2023-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1350.00</td>\n",
       "      <td>1270.00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>19.49</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.27</td>\n",
       "      <td>4.49</td>\n",
       "      <td>14.49</td>\n",
       "      <td>...</td>\n",
       "      <td>11.70</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.93</td>\n",
       "      <td>91.49</td>\n",
       "      <td>52.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>FOX</td>\n",
       "      <td>17.63</td>\n",
       "      <td>21.79</td>\n",
       "      <td>11.57</td>\n",
       "      <td>10.18</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.53</td>\n",
       "      <td>7.59</td>\n",
       "      <td>...</td>\n",
       "      <td>69.21</td>\n",
       "      <td>3.37</td>\n",
       "      <td>21.65</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>LNC</td>\n",
       "      <td>3.57</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>193.22</td>\n",
       "      <td>3.17</td>\n",
       "      <td>18.41</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>1999-06-21</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>FRC</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>11.98</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NWS</td>\n",
       "      <td>10.13</td>\n",
       "      <td>13.03</td>\n",
       "      <td>34.75</td>\n",
       "      <td>22.52</td>\n",
       "      <td>19.40</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.28</td>\n",
       "      <td>10.99</td>\n",
       "      <td>...</td>\n",
       "      <td>46.69</td>\n",
       "      <td>1.28</td>\n",
       "      <td>14.10</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>2010-11-15</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>DISH</td>\n",
       "      <td>4.74</td>\n",
       "      <td>26.15</td>\n",
       "      <td>2.47</td>\n",
       "      <td>10.02</td>\n",
       "      <td>12.84</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>6.80</td>\n",
       "      <td>...</td>\n",
       "      <td>131.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>33.78</td>\n",
       "      <td>3.09</td>\n",
       "      <td>-8.83</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>2000-03-22</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Market Cap (B)  Enterprise Value (B)  Trailing P/E  Forward P/E  \\\n",
       "0     AAPL         2540.00               2600.00         27.30        27.17   \n",
       "1     MSFT         2110.00               2070.00         31.43        26.11   \n",
       "2     AMZN         1020.00               1090.00          0.00        58.82   \n",
       "3     NVDA          671.07                669.81        156.14        60.24   \n",
       "4    GOOGL         1350.00               1270.00         23.10        19.49   \n",
       "..     ...             ...                   ...           ...          ...   \n",
       "498    FOX           17.63                 21.79         11.57        10.18   \n",
       "499    LNC            3.57                  7.67          0.00         2.50   \n",
       "500    FRC            2.63                  0.00          1.71        11.98   \n",
       "501    NWS           10.13                 13.03         34.75        22.52   \n",
       "502   DISH            4.74                 26.15          2.47        10.02   \n",
       "\n",
       "     PEG Ratio (5 yr expected)  Price/Sales (ttm)  Price/Book (mrq)  \\\n",
       "0                         2.72               6.72             44.85   \n",
       "1                         2.13              10.39             11.50   \n",
       "2                         2.12               1.98              7.01   \n",
       "3                         3.38              25.25             30.36   \n",
       "4                         1.15               4.90              5.27   \n",
       "..                         ...                ...               ...   \n",
       "498                       2.34               1.22              1.45   \n",
       "499                       0.00               0.19              1.15   \n",
       "500                       2.92               0.45              0.19   \n",
       "501                      19.40               1.02              1.25   \n",
       "502                      12.84               0.34              0.26   \n",
       "\n",
       "     Enterprise Value/Revenue  Enterprise Value/EBITDA  ...  \\\n",
       "0                        6.72                    20.34  ...   \n",
       "1                       10.12                    20.92  ...   \n",
       "2                        2.13                    28.53  ...   \n",
       "3                       24.83                   111.88  ...   \n",
       "4                        4.49                    14.49  ...   \n",
       "..                        ...                      ...  ...   \n",
       "498                      1.53                     7.59  ...   \n",
       "499                      0.41                     0.00  ...   \n",
       "500                      0.00                     0.00  ...   \n",
       "501                      1.28                    10.99  ...   \n",
       "502                      1.57                     6.80  ...   \n",
       "\n",
       "     Total Debt/Equity (mrq)  Current Ratio (mrq)  Book Value Per Share (mrq)  \\\n",
       "0                     195.87                 0.94                        3.58   \n",
       "1                      42.58                 1.93                       24.59   \n",
       "2                     116.36                 0.94                       14.26   \n",
       "3                      54.44                 3.52                        8.96   \n",
       "4                      11.70                 2.38                       19.93   \n",
       "..                       ...                  ...                         ...   \n",
       "498                    69.21                 3.37                       21.65   \n",
       "499                   193.22                 3.17                       18.41   \n",
       "500                     0.00                 0.00                       75.38   \n",
       "501                    46.69                 1.28                       14.10   \n",
       "502                   131.63                 0.76                       33.78   \n",
       "\n",
       "     Operating Cash Flow (ttm) (B)  Levered Free Cash Flow (ttm) (B)  \\\n",
       "0                           109.19                             84.73   \n",
       "1                            84.39                             44.61   \n",
       "2                            46.75                              0.01   \n",
       "3                             5.64                              4.53   \n",
       "4                            91.49                             52.53   \n",
       "..                             ...                               ...   \n",
       "498                           2.28                              1.86   \n",
       "499                           4.03                              2.23   \n",
       "500                           0.25                              0.00   \n",
       "501                           1.08                              0.61   \n",
       "502                           3.09                             -8.83   \n",
       "\n",
       "     Dividend Date  Ex-Dividend Date  Last Split Date  Fiscal Year Ends  \\\n",
       "0       2023-02-15        2023-02-09       2020-08-30        2022-09-23   \n",
       "1       2023-06-07        2023-05-16       2003-02-17        2022-06-29   \n",
       "2              NaN               NaN       2022-06-05        2022-12-30   \n",
       "3       2023-03-28        2023-03-06       2021-07-19        2023-01-28   \n",
       "4              NaN               NaN       2022-07-17        2022-12-30   \n",
       "..             ...               ...              ...               ...   \n",
       "498     2023-03-28        2023-02-27              NaN        2022-06-29   \n",
       "499     2023-04-30        2023-04-05       1999-06-21        2022-12-30   \n",
       "500     2023-02-08        2023-01-24              NaN        2022-12-30   \n",
       "501     2023-04-11        2023-03-13       2010-11-15        2022-06-29   \n",
       "502     2012-12-27        2012-12-11       2000-03-22        2022-12-30   \n",
       "\n",
       "     Most Recent Quarter (mrq)  \n",
       "0                   2022-12-30  \n",
       "1                   2022-12-30  \n",
       "2                   2022-12-30  \n",
       "3                   2023-01-28  \n",
       "4                   2022-12-30  \n",
       "..                         ...  \n",
       "498                 2022-12-30  \n",
       "499                 2022-12-30  \n",
       "500                 2022-12-30  \n",
       "501                 2022-12-30  \n",
       "502                 2022-12-30  \n",
       "\n",
       "[503 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapped_data = {}\n",
    "\n",
    "try:\n",
    "    missed_tickers = scrap_ticker(tickers, data_dict=scrapped_data, sleeptime=2, batch_interval=50)\n",
    "    if missed_tickers:\n",
    "        missed_tickers = rescrap_missed(missed_tickers, data_dict=scrapped_data, max_tries=2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    final_df, ticker_df = clean_df(scrapped_data, metrics, display_progress=False)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3af391f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file: s&p_2023-04-16.csv\n"
     ]
    }
   ],
   "source": [
    "filename = input(\"Enter filename to save as: \")\n",
    "if filename == '':\n",
    "    filename = 'portfolio'\n",
    "current_date = date.today().isoformat()\n",
    "final_df.to_csv(f'data/{filename}_{current_date}.csv')\n",
    "print(f'Saved to file: {filename}_{current_date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a3396c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n",
      "1062: Duplicate entry 'AAPL' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'MSFT' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'AMZN' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'NVDA' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'GOOG' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'TSLA' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'CDNS' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'MRNA' for key 'PRIMARY'\n",
      "1062: Duplicate entry 'IDXX' for key 'PRIMARY'\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "def get_value_from_json(json_file, key, sub_key=None):\n",
    "   '''\n",
    "   Function to read the json file for our app secret key\n",
    "   '''\n",
    "   try:\n",
    "       with open(json_file) as f:\n",
    "           data = json.load(f)\n",
    "           if sub_key:\n",
    "               return data[key][sub_key]\n",
    "           else:\n",
    "               return data[key]\n",
    "   except Exception as e:\n",
    "       print(\"Error: \", e)\n",
    "\n",
    "config = get_value_from_json(\"data/secrets.json\", \"mysql_connector\")\n",
    "\n",
    "# Connect to server on localhost\n",
    "try:\n",
    "    cnx = mysql.connector.connect(**config)\n",
    "    print('Connected to database')\n",
    "    cur = cnx.cursor()\n",
    "    insert_query = \"INSERT IGNORE INTO companies (Ticker, Name) VALUES (%s, %s)\"\n",
    "    for index, row in ticker_df.iterrows():\n",
    "        try:\n",
    "            data = (row['Ticker'], row['Name'].strip())\n",
    "            #print(f'Inserting {data}', end = ' ')\n",
    "            cur.execute(insert_query, data)\n",
    "            cnx.commit()\n",
    "            #print('Done')\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "finally:\n",
    "    print('Completed')\n",
    "    cur.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bef1d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n",
      "1062: Duplicate entry '2023-04-16-AAPL' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-MSFT' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-AMZN' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-NVDA' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-GOOG' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-TSLA' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-CDNS' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-MRNA' for key 'PRIMARY'\n",
      "1062: Duplicate entry '2023-04-16-IDXX' for key 'PRIMARY'\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cnx = mysql.connector.connect(**config)\n",
    "    print('Connected to database')\n",
    "    cur = cnx.cursor()\n",
    "    insert_query = '''INSERT IGNORE INTO statistics (Ticker, `Market Cap (B)`, `Enterprise Value (B)`, `Trailing P/E`,\n",
    "       `Forward P/E`, `PEG Ratio (5 yr expected)`, `Price/Sales (ttm)`,\n",
    "       `Price/Book (mrq)`, `Enterprise Value/Revenue`,\n",
    "       `Enterprise Value/EBITDA`, `Beta (5Y Monthly)`, `52 Week Change (%)`,\n",
    "       `S&P500 52-Week Change (%)`, `52 Week High`, `52 Week Low`,\n",
    "       `50-Day Moving Average`, `200-Day Moving Average`,\n",
    "       `Avg Vol 3 month (M)`, `Avg Vol 10 day (M)`, `Shares Outstanding`,\n",
    "       `Implied Shares Outstanding`, `Float`, `% Held by Insiders`,\n",
    "       `% Held by Institutions`, `Shares Short (M)`, `Short Ratio (M)`,\n",
    "       `Short % of Float`, `Short % of Shares Outstanding`, `Shares Short`,\n",
    "       `Forward Annual Dividend Rate`, `Forward Annual Dividend Yield (%)`,\n",
    "       `Trailing Annual Dividend Rate`, `Trailing Annual Dividend Yield (%)`,\n",
    "       `5 Year Average Dividend Yield`, `Payout Ratio (%)`,\n",
    "       `Last Split Factor (x:1)`, `Profit Margin (%)`,\n",
    "       `Operating Margin (ttm) (%)`, `Return on Assets (ttm) (%)`,\n",
    "       `Return on Equity (ttm) (%)`, `Revenue (ttm) (B)`,\n",
    "       `Revenue Per Share (ttm)`, `Quarterly Revenue Growth (yoy) (%)`,\n",
    "       `Gross Profit (ttm) (B)`, `EBITDA (B)`,\n",
    "       `Net Income Avi to Common (ttm) (B)`, `Diluted EPS (ttm)`,\n",
    "       `Quarterly Earnings Growth (yoy) (%)`, `Total Cash (mrq) (B)`,\n",
    "       `Total Cash Per Share (mrq)`, `Total Debt (mrq) (B)`,\n",
    "       `Total Debt/Equity (mrq)`, `Current Ratio (mrq)`,\n",
    "       `Book Value Per Share (mrq)`, `Operating Cash Flow (ttm) (B)`,\n",
    "       `Levered Free Cash Flow (ttm) (B)`, `Dividend Date`, `Ex-Dividend Date`,\n",
    "       `Last Split Date`, `Fiscal Year Ends`, `Most Recent Quarter (mrq)`) \n",
    "       VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "       %s)'''\n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            data = (row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], \n",
    "                row[10], row[11], row[12], row[13], row[14], row[15], row[16], row[17], row[18], \n",
    "                row[19], row[20], row[21], row[22], row[23], row[24], row[25], row[26], row[27], \n",
    "                row[28], row[29], row[30], row[31], row[32], row[33], row[34], row[35], row[36], \n",
    "                row[37], row[38], row[39], row[40], row[41], row[42], row[43], row[44], row[45], \n",
    "                row[46], row[47], row[48], row[49], row[50], row[51], row[52], row[53], row[54], \n",
    "                row[55], row[56], row[57], row[58], row[59], row[60])\n",
    "            #print(f'Inserting {data}', end = ' ')\n",
    "            cur.execute(insert_query, data)\n",
    "            cnx.commit()\n",
    "            #print('Done')\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "finally:\n",
    "    print('Completed')\n",
    "    cur.close()\n",
    "    cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "94b36ee82f075bfd65a5162390b3b714440a4070c5983427e0c848ed56faa685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
